{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24be38d-ce1c-4854-9910-b039cdded7c2",
   "metadata": {},
   "source": [
    "# Benchmarking the TextCNN Model\n",
    "> Sample code to run prediction and evaluate a TextCNN model with Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0cc13-b755-4f47-ba05-3db9a2d96916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_update = pd.read_csv(\"dataset_mRFP.csv\")\n",
    "sequence = df_update['Sequence'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91df60e-f87e-4f71-978f-1fc2009de66e",
   "metadata": {},
   "source": [
    "## Creating Fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa7f2d-882e-4781-a11a-5ee7b7f9790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16daa1-83de-4aff-9f90-77d17a6a13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fragmentation import KmerFragmenter\n",
    "\n",
    "fragmenter = KmerFragmenter()\n",
    "sequences = df_update['Sequence'].values.tolist()\n",
    "sequences = [x.replace(\"T\", \"U\") for x in sequences]\n",
    "fragments = fragmenter.split_words(sequences,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e93d7-b029-4d03-9663-f6ff63e1c2ee",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "These will be used to train the CNN model. Here we are using a simple Word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fabb4-bbca-4437-abcc-e3cbc793e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vectorizer import Vectorizer\n",
    "\n",
    "vector_space_embedder = Vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a9c4b-57e9-4053-b27f-b36a9484e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "word2vec_path = './sg_1_vs_128_ws_5.model'\n",
    "mod = models.Word2Vec.load(word2vec_path)\n",
    "vector_space_embedder.model = mod\n",
    "vector_space_embedder.rna_fragments = fragments\n",
    "vector_stack_w2v = vector_space_embedder.create_vector_concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e498ca-0fff-41e2-b86b-8a5b02333e5b",
   "metadata": {},
   "source": [
    "### Save word2vec matrix for CNN model training\n",
    "> See `benchmarks/textcnn` for training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35cc43-51ae-466e-9d8e-78a304e74825",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    np.save(\"dataset_mRFP_embeddings.npy\", vector_stack_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306a3cb-4f5c-48e2-8734-425ae8041fb2",
   "metadata": {},
   "source": [
    "## Import Trained CNN model\n",
    "We trained the model with the embeddings from above by running the `UDS-CodonBERT/benchmarks/textcnn/main.py` script.\n",
    "\n",
    "Below we import the saved model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3418d-46b1-42c3-bf6b-2a56f66c6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        V = args.get(\"embed_num\")\n",
    "        D = args.get(\"embed_dim\")\n",
    "        C = 1\n",
    "        Ci = 1\n",
    "        Co = args.get(\"kernel_num\")\n",
    "        Ks = args.get(\"kernel_sizes\")\n",
    "\n",
    "        # self.embed = nn.Embedding(V, D)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(args.get(\"dropout\"))\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "\n",
    "        if args.get(\"static\"):\n",
    "            self.embed.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [\n",
    "            F.relu(conv(x)).squeeze(3) for conv in self.convs\n",
    "        ]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fbecc-304c-4bbd-a8eb-98f07a53050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"embed_num\": 6,\n",
    "    \"embed_dim\": 128,\n",
    "    \"kernel_num\": 100,\n",
    "    \"kernel_sizes\": [3, 4, 5],\n",
    "    \"dropout\": 0.1,\n",
    "    \"static\": False\n",
    "}\n",
    "\n",
    "X_test = np.load(\"\")\n",
    "y_test = np.load(\"\")\n",
    "cnn = CNN_Text(args)\n",
    "cnn.load_state_dict(torch.load(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760869ec-c01b-4963-9d76-e75fed3cd3c3",
   "metadata": {},
   "source": [
    "## Benchmark system\n",
    "\n",
    "> Pass test cases into neural network and measure correlation with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6660ed2b-8fcb-44ec-b106-7d2511f1f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = cnn(torch.tensor(X_test)).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a19864-ea8b-4cdb-8978-fe2e5c02cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_test_acc(y_test, y_pred):\n",
    "    spr = stats.spearmanr(y_test, y_pred)[0]\n",
    "    acc = mean_squared_error(y_test, y_pred)\n",
    "    return acc, spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16802b8-c43c-464b-ae5f-f24aa4f34926",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, spr = train_test_acc(y_test, test_preds)\n",
    "print(f\"Spearman correlation: {round(spr, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f5eff-3adf-4db1-9a4e-5edfb44dc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "p1 = max(max(test_preds), max(y_test))\n",
    "p2 = min(min(test_preds), min(y_test))\n",
    "\n",
    "ax.scatter(y_test, test_preds)\n",
    "ax.plot([p1, p2], [p1, p2], \"r-\")\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (codonbert)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
